\section{Literature review}
\label{sec:lit-review}

Vision-based control solutions for UAVs on low-cost platforms have gained significant attention recently due to the increasing demand for cost-effective and efficient aerial applications. This literature review summarizes the existing research in this field and highlights the essential findings and challenges.

A significant amount of research has focused on developing algorithms for real-time image processing, focusing on improving the accuracy and robustness of tracking solutions for UAV applications.
In \cite{gomez-balderas2012}, a computer
vision algorithm for position measurement and velocity estimation using optical flow is proposed for tracking ground-moving targets.
In \cite{bevilacqua2016}, the focus is to solve the problem of tracking and following a generic human target by a drone in a natural, possibly dark scene without relying on colour information.
In \cite{rysdyk2003}, several algorithms are developed to create path-following mechanisms that maintain a constant line of sight with the target.
These studies attempt to develop solutions that can be applied to any platform regardless of any preexisting autopilot control in the UAVs.
They focus on low-level software implementations of complex control theory topics with advanced mathematics.
In contrast, this thesis aims to abstract as much as possible both the control technics and the computer vision mechanisms of detection and tracking to focus on presenting an easy-to-use platform that can employ already developed algorithms and combine them to make robust systems with a lower threshold of knowledge.

Other studies have already centred on developing lower-cost solutions for more accessible platforms. Many have used the Parrot \emph{AR.Drone} camera-enabled quadcopter that allows controlling through WiFi from an external offboard computer.
In \cite{bartak2015}, \cite{chakrabarty2016}, \cite{pestana2013}, and \cite{haag2015}, the \emph{AR.Drone} is used for implementing object tracking and following solutions in different environments and conditions with a higher emphasis on the type of trackers employed to achieve a robust visual following mechanism.
In \cite{hernandez2013}, \cite{lugo2014}, and \cite{bristeau2011}, there is a higher focus on exposing the capabilities of the \emph{AR.Drone} as a platform to develop custom control solutions utilizing the navigation and control technology and the low-cost sensors already embedded in the vehicle.
The main difference between the platform used in the mentioned research and the PX4 platform that is the target of this thesis is that the \emph{AR.Drone} is offered as-is as a concrete low-cost vehicle for which autonomous guidance and control can be developed, while the PX4 platform is part of an extensive environment that encompasses everything from the minimum essential hardware to the low-level autopilot mechanisms to the high-level control commands and allows complete personalization at each layer of the system.

As the PX4 platform has been available for less than a decade and has only become a widely-recognized standard in the drone industry since 2020, there is still little research on its ecosystem, and fewer specific computer-vision projects have been developed.
However, some studies share some of the possibilities that the PX4 software and the Pixhawk flight controllers offer in the field.
In \cite{sizkouhi2022}, aerial images are analyzed in real-time and fed to a deep-learning architecture to calculate optimal flight paths.
In \cite{naufal2022}, a vision-based precision landing method for quadcopter drones is developed on the Pixhawk flight controller to prevent crashes on landing.

Another vital advantage of the PX4 platform over other available platforms is its compatibility with a wide range of simulators that allow the development of complex control systems in changing environments with less need for expensive, time-consuming, and meticulous testing of the correct integration of the hardware and software components through real-world flight tests of UAVs that traditional development often entails.
Some studies have obtained results in this area of the ecosystem.
In \cite{garcia2022}, the Gazebo simulator and the PX4 software are used to develop a system for simulating realistic navigation conditions for obstacle avoidance.
In \cite{chen2022}, a similar ROS-Gazebo environment serves as the basis for designing fault-tolerant controllers that can recover from rotor failure.
In \cite{huynh2022}, the aim is to integrate a photo-realistic environment simulator with a flight-dynamics simulator to develop full autonomy in the Pixhawk autopilot board.
These represent only some of the possible applications of such a complete ecosystem for developing solutions.

In conclusion, vision-based control solutions are still a relatively new field in the broader topic of autonomous guidance and navigation for UAVs.
Some older low-cost platforms have been more extensively researched as the basis for developing accessible control systems driven by computer vision.
However, for PX4-driven UAVs, there are still many unexplored possibilities when it comes to applying the simulator capabilities of the platform to the development of vision-based control solutions and taking advantage of modern rendering techniques to simulate complex detection and tracking scenarios that reduce the need for demanding real-world flight tests.