\section{Literature review}
\label{sec:lit-review}

% Vision-based control solutions for UAVs on low-cost platforms have gained significant attention recently due to the increasing demand for cost-effective and efficient aerial applications. This literature review summarizes the existing research in this field and highlights the essential findings and challenges.

% A significant amount of research has focused on developing algorithms for real-time image processing, focusing on improving the accuracy and robustness of tracking solutions for UAV applications.
% In \cite{gomez-balderas2012}, a computer
% vision algorithm for position measurement and velocity estimation using optical flow is proposed for tracking ground-moving targets.
% In \cite{bevilacqua2016}, the focus is to solve the problem of tracking and following a generic human target by a drone in a natural, possibly dark scene without relying on colour information.
% In \cite{rysdyk2003}, several algorithms are developed to create path-following mechanisms that maintain a constant line of sight with the target.
% These studies attempt to develop solutions that can be applied to any platform regardless of any preexisting autopilot control in the UAVs.
% They focus on low-level software implementations of complex control theory topics with advanced mathematics.
% In contrast, this thesis aims to abstract as much as possible both the control technics and the computer vision mechanisms of detection and tracking to focus on presenting an easy-to-use platform that can employ already developed algorithms and combine them to make robust systems with a lower threshold of knowledge.

% Other studies have already centred on developing lower-cost solutions for more accessible platforms. Many have used the Parrot \emph{AR.Drone} camera-enabled quadcopter that allows controlling through WiFi from an external offboard computer.
% In \cite{bartak2015}, \cite{chakrabarty2016}, \cite{pestana2013}, and \cite{haag2015}, the \emph{AR.Drone} is used for implementing object tracking and following solutions in different environments and conditions with a higher emphasis on the type of trackers employed to achieve a robust visual following mechanism.
% In \cite{hernandez2013}, \cite{lugo2014}, and \cite{bristeau2011}, there is a higher focus on exposing the capabilities of the \emph{AR.Drone} as a platform to develop custom control solutions utilizing the navigation and control technology and the low-cost sensors already embedded in the vehicle.
% The main difference between the platform used in the mentioned research and the PX4 platform that is the target of this thesis is that the \emph{AR.Drone} is offered as-is as a concrete low-cost vehicle for which autonomous guidance and control can be developed, while the PX4 platform is part of an extensive environment that encompasses everything from the minimum essential hardware to the low-level autopilot mechanisms to the high-level control commands and allows complete personalization at each layer of the system.

% As the PX4 platform has been available for less than a decade and has only become a widely-recognized standard in the drone industry since 2020, there is still little research on its ecosystem, and fewer specific computer-vision projects have been developed.
% However, some studies share some of the possibilities that the PX4 software and the Pixhawk flight controllers offer in the field.
% In \cite{sizkouhi2022}, aerial images are analyzed in real-time and fed to a deep-learning architecture to calculate optimal flight paths.
% In \cite{naufal2022}, a vision-based precision landing method for quadcopter drones is developed on the Pixhawk flight controller to prevent crashes on landing.

% Another vital advantage of the PX4 platform over other available platforms is its compatibility with a wide range of simulators that allow the development of complex control systems in changing environments with less need for expensive, time-consuming, and meticulous testing of the correct integration of the hardware and software components through real-world flight tests of UAVs that traditional development often entails.
% Some studies have obtained results in this area of the ecosystem.
% In \cite{garcia2022}, the Gazebo simulator and the PX4 software are used to develop a system for simulating realistic navigation conditions for obstacle avoidance.
% In \cite{chen2022}, a similar ROS-Gazebo environment serves as the basis for designing fault-tolerant controllers that can recover from rotor failure.
% In \cite{huynh2022}, the aim is to integrate a photo-realistic environment simulator with a flight-dynamics simulator to develop full autonomy in the Pixhawk autopilot board.
% These represent only some of the possible applications of such a complete ecosystem for developing solutions.

% In conclusion, vision-based control solutions are still a relatively new field in the broader topic of autonomous guidance and navigation for UAVs.
% Some older low-cost platforms have been more extensively researched as the basis for developing accessible control systems driven by computer vision.
% However, for PX4-driven UAVs, there are still many unexplored possibilities when it comes to applying the simulator capabilities of the platform to the development of vision-based control solutions and taking advantage of modern rendering techniques to simulate complex detection and tracking scenarios that reduce the need for demanding real-world flight tests.


Vision-based control solutions for UAVs on low-cost platforms have garnered significant attention in recent years, driven by the growing demand for cost-effective and efficient aerial applications. This literature review provides an overview of the existing research in this field, highlighting key findings and challenges.

A substantial body of research has focused on developing real-time image processing algorithms to enhance the accuracy and robustness of tracking solutions for UAV applications. For instance, in \cite{gomez-balderas2012}, a computer vision algorithm utilizing optical flow is proposed for tracking ground-moving targets, enabling position measurement and velocity estimation. Similarly, \cite{bevilacqua2016} addresses the problem of tracking and following generic human targets in natural, possibly dark scenes without relying on colour information. In \cite{rysdyk2003}, several algorithms are developed to create path-following mechanisms that maintain a constant line of sight with the target. These studies attempt to develop solutions that can be applied to any platform regardless of any preexisting autopilot control in the UAVs.
They focus on low-level software implementations of complex control theory topics with advanced mathematics.
In contrast, this thesis aims to abstract control techniques and computer vision mechanisms to present an easy-to-use platform that combines existing algorithms for robust systems with a lower threshold of knowledge, focusing on the integration between software and hardware.

Due to the fact that the PX4 platform has been available for less than a decade, and despite its recognition as a widely-used standard in the drone industry since 2020, there is limited research done on this ecosystem, and few computer vision projects have focused specifically on this platform. However, some studies demonstrate the possibilities offered by the PX4 software and the Pixhawk flight controllers developed for it. In \cite{sizkouhi2022}, aerial images are analyzed in real-time and fed to a deep learning architecture to calculate optimal flight paths. \cite{naufal2022} focuses on developing a vision-based precision landing method for quadcopter drones using the Pixhawk flight controller to prevent crashes during landing.

In contrast, other comparable accessible platforms that have been available for a longer period have been explored further on vision-based control projects. Specifically, the Parrot \emph{AR.Drone} camera-enabled quadcopter, which exposes an API that allows control through WiFi from an external offboard computer is the most widely used.
In \cite{bartak2015}, \cite{chakrabarty2016}, \cite{pestana2013}, and \cite{haag2015}, the \emph{AR.Drone} is utilized for implementing object tracking and following solutions in various environments and conditions, with a particular emphasis on the type of trackers employed to achieve a robust visual following mechanism. 
In \cite{hernandez2013}, \cite{lugo2014}, and \cite{bristeau2011}, researchers focus on leveraging the capabilities of the \emph{AR.Drone} as a platform to develop custom control solutions, utilizing embedded navigation and control technology along with low-cost sensors. It is worth noting that the key distinction between the platform used in the mentioned research and the PX4 platform targeted in this thesis is that the \emph{AR.Drone} is offered as a complete low-cost vehicle for developing autonomous guidance and control, whereas the PX4 platform provides a comprehensive environment allowing for enormous customization at each layer of the system.

Another significant advantage of the PX4 platform over other available platforms is its compatibility with a wide range of simulators, enabling the development of complex control systems in diverse environments. This reduces the need for expensive, time-consuming, and meticulous real-world flight testing. Several studies have explored this aspect of the PX4 ecosystem. 
For example, \cite{garcia2022} employs the Gazebo simulator and the PX4 software to develop a system for simulating realistic navigation conditions for obstacle avoidance.
In \cite{chen2022}, a ROS-Gazebo environment serves as the foundation for designing fault-tolerant controllers capable of recovering from rotor failure. 
Moreover, \cite{huynh2022} aims to integrate a photo-realistic environment simulator with a flight dynamics simulator to achieve full autonomy in the Pixhawk autopilot board. 
These examples demonstrate the potential applications of the comprehensive PX4 ecosystem for developing control algorithms.


The literature reviewed indicates that the PX4 platform offers unique advantages, such as its extensibility, compatibility with a wide range of simulators, and the ability to personalize each layer of the system. While previous research has primarily focused on low-cost platforms like the \emph{AR.Drone}, there is a clear gap in the exploration of the PX4 ecosystem and its potential for vision-based control solutions.

The studies mentioned in the literature review highlight various applications of vision-based control on the PX4 platform, such as optimal flight path calculation, precision landing, obstacle avoidance, and fault-tolerant control. However, these examples only scratch the surface of what can be achieved with the comprehensive PX4 ecosystem.

Considering the relatively recent emergence of the PX4 platform as a widely-recognized standard, there is ample room for further research and development. The simulator capabilities of the platform provide a valuable opportunity to explore and refine vision-based control algorithms in a virtual environment, enabling more efficient and cost-effective system development.

By leveraging the PX4 ecosystem, researchers can focus on abstracting complex control techniques and computer vision mechanisms, making them more accessible to a broader range of users. This approach facilitates the development of easy-to-use platforms that integrate existing algorithms and combine them to create robust vision-based control systems. The goal is to lower the knowledge threshold required to implement such systems and enable wider adoption of vision-based control solutions for UAVs.


In conclusion, vision-based control solutions remain a relatively new field within the broader topic of autonomous guidance and navigation for UAVs. While some older low-cost platforms have been extensively researched as the basis for accessible computer vision-driven control systems, there are still numerous unexplored possibilities for applying the simulator capabilities of the PX4 platform to develop vision-based control solutions and leverage modern rendering techniques for simulating complex detection and tracking scenarios. This approach reduces the reliance on demanding real-world flight tests.