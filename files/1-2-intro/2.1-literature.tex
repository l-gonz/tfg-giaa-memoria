\section{Literature review}
\label{sec:lit-review}



Vision-based control solutions for UAVs on low-cost platforms have garnered significant attention in recent years, driven by the growing demand for cost-effective and efficient aerial applications. This literature review provides an overview of the existing research in the fields of tracking and following aboard UAVs and available hardware and software platforms for control, highlighting key findings and challenges.

A substantial body of research has focused on developing real-time image processing algorithms to enhance the accuracy and robustness of tracking solutions for UAV applications. For instance, in \cite{gomez-balderas2012}, a computer vision algorithm utilising optical flow is proposed for tracking ground-moving targets, enabling position measurement and velocity estimation. Similarly, \cite{bevilacqua2016} addresses the problem of tracking and following generic human targets in natural, possibly dark scenes without relying on colour information. In \cite{rysdyk2003}, several algorithms are developed to create path-following mechanisms that maintain a constant line of sight with the target. These studies attempt to develop solutions that can be applied to any platform regardless of any preexisting autopilot control in the UAVs.
They focus on low-level software implementations of complex control theory topics with advanced mathematics.
In contrast, this thesis aims to abstract flight control techniques and computer vision mechanisms to present an easy-to-use platform that combines existing algorithms to achieve robust systems, focusing on the integration between software and hardware.

Due to the fact that the PX4 platform has been available for less than a decade, and despite its recognition as a widely-used standard in the drone industry since 2020, there is limited research done on this ecosystem, and few computer vision projects have explicitly focused on this platform. However, some studies demonstrate the possibilities offered by the PX4 software and the Pixhawk flight controllers that run it. In \cite{sizkouhi2022}, aerial images are analysed in real-time and fed to a deep learning architecture to calculate optimal flight paths. \cite{naufal2022} focuses on developing a vision-based precision landing method for quadcopter drones using the Pixhawk flight controller to prevent crashes during landing.

In contrast, other comparable accessible platforms that have been available longer have been explored further on vision-based control projects. Specifically, the Parrot \emph{AR.Drone} camera-enabled quadcopter is the most widely used. The Parrot platform exposes an API that allows WiFi control from an external offboard computer.
In \cite{bartak2015}, \cite{chakrabarty2016}, \cite{pestana2013}, and \cite{haag2015}, the \emph{AR.Drone} is utilised for implementing object tracking and following solutions in various environments and conditions, emphasising particularly the type of trackers employed to achieve a robust visual following mechanism. 
In \cite{hernandez2013}, \cite{lugo2014}, and \cite{bristeau2011}, researchers focus on leveraging the capabilities of the \emph{AR.Drone} as a platform to develop custom control solutions using embedded navigation, control technology and low-cost sensors. It is worth noting that the key distinction between the platform used in the mentioned research and the PX4 platform targeted in this thesis is that the \emph{AR.Drone} is offered as a fully-built low-cost vehicle for developing high-level autonomous guidance and control without concern for hardware interactions. In contrast, the PX4 platform provides a more comprehensive environment, allowing for customisation at each system layer, from the basic sensors to the high-level control software

Another significant advantage of the PX4 platform over other available platforms is its compatibility with a wide range of simulators, enabling the development of complex control systems in diverse environments. These simulators reduce the need for expensive, time-consuming, and meticulous real-world flight testing. Several studies have explored this aspect of the PX4 ecosystem. 
For example, \cite{garcia2022} employs the Gazebo simulator and the PX4 software to develop a system for simulating realistic navigation conditions for obstacle avoidance.
In \cite{chen2022}, a ROS-Gazebo environment serves as the foundation for designing fault-tolerant controllers capable of recovering from rotor failure. 
Moreover, \cite{huynh2022} aims to integrate a photo-realistic environment simulator with a flight dynamics simulator to achieve full autonomy in the Pixhawk autopilot board. 
These examples demonstrate the potential applications of the extensive PX4 ecosystem for developing control algorithms.


In summary, the literature reviewed indicates that the PX4 platform offers unique advantages stemming from its open-source nature, such as its extensibility, compatibility with a wide range of simulators, and the ability to personalise each layer of the system. While previous research has primarily focused on low-cost platforms like the \emph{AR.Drone}, there are many avenues left to explore in the PX4 ecosystem and its potential for vision-based control solutions. The studies mentioned highlight various applications of vision-based control on the PX4 platform, such as optimal flight path calculation, precision landing, obstacle avoidance, and fault-tolerant control. However, these examples only scratch the surface of what can be achieved with the comprehensive PX4 ecosystem.

Considering the relatively recent emergence of the PX4 platform as a widely recognised standard, there is ample room for further research and development. The platform's simulator capabilities provide a valuable opportunity to explore and refine vision-based control algorithms in a virtual environment, enabling more efficient and cost-effective development.

By leveraging the PX4 ecosystem, researchers can focus on abstracting complex control techniques and computer vision mechanisms, making them more accessible to a broader range of users. This approach facilitates the development of easy-to-use platforms that integrate existing algorithms and combine them to create robust vision-based control systems. The goal is to lower the knowledge threshold required to implement such systems and enable wider adoption of vision-based control solutions for UAVs.


In conclusion, vision-based control solutions remain a relatively new field within the broader topic of autonomous guidance and navigation for UAVs. While some older low-cost platforms have been extensively researched as the basis for accessible computer vision-driven control systems, there are still numerous unexplored possibilities for applying the simulator capabilities of the PX4 platform to develop vision-based control solutions and leverage modern rendering techniques for simulating complex detection and tracking scenarios. This approach reduces the reliance on demanding real-world flight tests.