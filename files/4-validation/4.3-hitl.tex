\section{PX4 HITL simulation and validation}
\label{sec:test-4-hitl}

% Setup:    build drone, HITL configuration
% Test:     - AirSim + follow on Windows + Pixhawk
%           - QGroundControl (without program running)
%           - PX4 to computer connection
%           - RC on AirSim
% Results:  images of wiring computer-Pixhawk

The aim of this section is to validate the transition from using a simulated version of the flight stack running on Linux (PX4's software-in-the-loop simulation) to using a physical Pixhawk board with simulated input and output to test the flight controller interaction with the developed program.
To do so, the aim is to be able to run the follow solution to send control commands through the Pixhawk board and observe the movement of the vehicle in the AirSim simulator in the same manner as in the previous section.


QGroundControl contains a specific quadcopter HITL airframe configuration that sets up the board with all the required parameters to activate this new hardware-in-the-loop mode.
It automatically detects the Pixhawk 4 board when connected to the computer through its Micro-USB port.
It is also required to make changes to the AirSim configuration for the simulator to work with HITL mode, namely, activating the option to accept connections through serial.
To test the complete system configuration for HITL described in section \ref{sec:devenv} and outlined in figure \ref{fig:hitl-connections}, the Pixhawk board needs an additional channel of communication to the computer dedicated to the Mavlink exchange with the dronecontrol application.
The board will therefore have both a direct cable connection to the computer and a telemetry radio on its \texttt{TELEM1} port with a wireless link to its counterparty radio connected to the computer.
Since the AirSim simulator requires a higher update rate than the dronecontrol application, it will employ the faster, cabled link.
The simulator can automatically connect to the board when it is started once the \texttt{UseSerial} option in the AirSim settings is set to true.
The Dronecontrol program will connect through the telemetry radio by specifying the serial port and corresponding baudrate when launching the application.
Since the flight stack is now running on a physical controller, it is possible to add an RC antenna to the \texttt{PPM RC} port of the board to be able to fly the vehicle with a remote control unit after it has been bound to the receiver\footnote{\url{https://docs.px4.io/main/en/config/radio.html}}.
By configuring one of the switches in the RC unit to change to PX4's offboard flight mode, additional checks to the safety measures of interrupting autonomous flight on flight mode changes or loss of signal from the RC controller can be carried out.
Figure \ref{fig:hitl-setup-picture} shows all the connections mentioned.

\begin{figure}
  \centering
  \includegraphics[width=\textwidth, keepaspectratio]{img/hitl-setup-picture.jpg}
  \caption{Pixhawk 4 board connected to the Raspberry Pi running the dronecontrol application and the Windows computer running the AirSim simulator, with telemetry radio for QGroundControl and RC receiver for manual control}
  \label{fig:hitl-setup-picture}
\end{figure}

After all the necessary connections are set up, the program can be started with the following command:
\mintinline{bash}{python -m dronecontrol follow --sim --serial COM[X]:57600}, where the exact COM port will vary depending on the particular USB port to which the telemetry radio is connected.


\subsection{PX4 HITL validation with Raspberry Pi}
\label{sec:test-5-rpi}

% Setup:    Raspberry Pi installation, RPi-Pixhawk connection
% Test:     - AirSim + follow on RPi + Pixhawk
%           - Serial connection
% Results:  wiring, performance metrics

The next step in the transition from a fully simulated environment to real flight is to connect the future onboard computer, the Raspberry Pi 4, to the Pixhawk flight controller and proceed with more realistic tests on the exact hardware that will be controlling the drone.
The main characteristics of the Raspberry Pi that have to be ensured to be able to progress further towards autonomous flight are:
\begin{enumerate}
    \item Capacity to function when power is provided from a battery
    \item Stability of serial connection to the Pixhawk board
    \item Ability to run the dronecontrol application and all its dependencies
    \item Connection to an external camera
    \item Performance of the computer vision algorithms with reduced processing power
\end{enumerate}

% installation
% xrdp
% battery tests

The complete installation process of all the required libraries and dependencies for the Raspberry Pi is explained in appendix \ref{app:install-dronecontrol-rpi}.
The most convenient method of controlling the small computer is through a remote desktop connection, where the screen contents and mouse and keyboard input are transmitted through a local network.
This way, accessing the Pi's desktop from the ground station computer is possible even during flight.
One option to achieve this is XRDP\footnote{\url{http://xrdp.org/}}, an open-source implementation of a Microsoft Remote Desktop Protocol server compatible with the Raspberry OS.

The first hardware connection to test is the power supply to the Raspberry.
As detailed in section \ref{subsec:onboard}, the selected method for powering the companion computer in the onboard configuration is through a secondary battery.
The connection will be made with a USB to USB-C cable from the battery to the Raspberry Pi.
The intent behind testing the power supply at this point in this process is to verify that it will be suitable for its purpose before it is actually needed to power the computer onboard the vehicle.
This power source must provide enough power to both maintain the processor running at an appropriate speed and provide power to the external camera in turn, which will be attached to the Pi's board and extract power from it.

A similar connector provides a channel for the Mavlink communication between the flight controller and the onboard computer.
In this case, one end of the connector is attached to the \texttt{TELEM2} port in the board and the TX/RX pins are attached to the UART pins on the Raspberry's GPIO header.
For this serial connection to work, both the flight controller and the companion computer need some additional configuration.
The Pixhawk needs to be configured through QGroundControl to enable a secondary Mavlink channel as, by default, only the \texttt{TELEM1} port used by the telemetry radio is configured.
The necessary parameters to modify and their values are collected in table \ref{tab:telem2-params}.
On the Raspberry side, the serial port comes configured to be used as a terminal instead of as a hardware serial port.
This can be fixed through the \texttt{raspi-config} command-line utility with the following steps: Interface options -> Serial Port -> Disable login shell, enable serial port hardware.
After that, the \texttt{/dev/serial0} address can be used to communicate to the device attached to the UART pins at the baudrate configured through QGroundControl.
The \texttt{raspi-config} tool and the connector used between the flight controller and the companion computer are shown in figure \ref{fig:serial-connection}.

\begin{table}[h!]
 \begin{center}
  \begin{tabular}{l|l}
    Parameter name & Value \\ \hline
    MAV\_1\_CONFIG & TELEM2 \\
    SER\_TEL2\_BAUD & 921600 \\
  \end{tabular}
  \caption{PX4 parameters that need to be configured to enable Mavlink communication through the secondary telemetry port}
  \label{tab:telem2-params}
 \end{center}
\end{table}


\begin{figure}
  \centering
  \makebox[\textwidth][c]{
  \includegraphics[width=.615\textwidth, keepaspectratio]{img/raspi-config.png}
  \includegraphics[width=.385\textwidth, keepaspectratio]{img/rpi-pixhawk-serial.jpg}}
  \caption{a) Picture of Raspberry's \texttt{raspi-config} and b) close-up of Pixhawk to Pi cable connection}
  \label{fig:serial-connection}
\end{figure}

The test camera utility will be used to validate this configuration.
At this point, the only physical connection to the ground station running AirSim or QGroundControl is through the development-only micro-USB port in the Pixhawk.
The results from running: \\
\begin{listing}[h!]
    \begin{minted}[breaklines, fontsize=\footnotesize, baselinestretch=1]{bash}
dronecontrol tools test-camera --hardware /dev/serial0:921600 --sim <AirSim host IP> --pose-detection
    \end{minted}
\end{listing}\\
can be seen on figure \ref{fig:rpi-airsim-test}.
On the right side, the remote connection to the Raspberry's desktop shows the output of the dronecontrol program running the pose detection algorithm on the images received from the simulator.
On the left side, the AirSim simulator shows the vehicle's movements as it reacts to the input from the flight controller and the companion computer.

\begin{figure}
  \centering
  \includegraphics[width=\textwidth, keepaspectratio]{img/airsim-rpi-test.png}
  \caption{Left: AirSim simulator on Windows host, right: RPi desktop with Dronecontrol application and pose output}
  \label{fig:rpi-airsim-test}
\end{figure}

\subsection{Performance analysis}
\label{subsec:performance}

The main question left to answer before the vehicle can take to the air with this hardware and software is whether the less powerful processor in the Raspberry Pi 4b, a quad-core ARM Cortex-A72 64-bit SoC running at 1.5GHz, can handle the detection and tracking algorithms with enough performance to get similar results to those obtained with simulated hardware and achieve good reactions to real-time movement.
To do that, the average time that the program spends on each task in the running loop can be calculated and analyzed for different scenarios.
Then it will be possible to estimate the maximum speed at which the person being followed by the algorithm can move.

% Make sure there's a good loop diagram in that section pointed below, and that the enumerated parts are explained in detail
% Match numbers to added figures
From the follow loop presented in section \ref{sec:follow}, it is possible to divide the processing cost into several areas that can be measured independently: image processing, offboard control, manual input, and released thread (sleep).

\begin{figure}
  \centering
  \includegraphics[width=.9\textwidth, keepaspectratio]{img/sitl-performance.png}
  \caption{Average percentages of a loop spent by each task in the follow solution with their corresponding average absolute times in seconds.}
  \label{fig:perf-sitl-sim}
\end{figure}

Figure \ref{fig:perf-sitl-sim} shows the time used for each task on an average run of the follow solution with simulated hardware (PX4 running in SITL mode with AirSim).
The time measurements have been taken by calculating the time difference between each statement's start and end and averaging across every iteration of the main loop.
The main cost in time of each execution is found in the image processing task, which takes around 89\% of the total loop time to run.
This is where the most significant differences in performance will come from between the simulated hardware and the solution running in the Pixhawk 4 + Raspberry Pi combination.
This image analysis process can be further subdivided to get a finer degree of control over how much time each part takes.
The three subtasks that makeup image processing are:
\begin{enumerate}
    \item Get frame: request a new frame from the video source.
    \item Process pose: send the frame to MediaPipe library for detection and tracking.
    \item Detect: calculate bounding box coordinates and define whether it is a valid pose.
\end{enumerate}

This further division is also shown in figure \ref{fig:perf-sitl-sim}, with each of these subtasks taking 40\%, 48\%, and 1\% of the total image processing time, respectively.
The total average time for each run of the follow loop is then 0.094 seconds, which results in an average performance of 10.5 FPS (frames-per-second).

Similar measurements have been taken for hardware combinations with different degrees of simulation, running the follow solution with offboard mode enabled and connected to the AirSim simulator.
These are:
\begin{enumerate}
    \item All simulated hardware: PX4 on SITL mode + dronecontrol on standalone computer + images from AirSim simulator video source.
    \item Simulated hardware with real images: PX4 on SITL mode + dronecontrol on standalone computer + images from the attached camera as video source.
    \item Test hardware with AC power supply: PX4 on HITL mode on Pixhawk 4 + dronecontrol on Raspberry Pi + images from the attached camera as video source.
    \item Test hardware with battery: PX4 on HITL mode on Pixhawk 4 + dronecontrol on Raspberry Pi powered by battery + images from the attached camera as video source.
\end{enumerate}


\begin{figure}
  \centering
  \includegraphics[width=\textwidth, keepaspectratio]{img/performance-graph.png}
  \caption{Average FPS and time spent on each task per iteration of the follow solution for the different hardware configurations.}
  \label{fig:perf-analysis}
\end{figure}


Figure \ref{fig:perf-analysis} shows the averages of the measurements taken for all the hardware combinations analyzed.
In the first test, it can be observed that the retrieval of each new frame from the AirSim simulator takes a much longer time than when an external camera is used.
This is because the simulation running on Unreal Engine is also limited in performance to what the computer can offer, which is not a cost that will be reflected when the simulation engine is no longer needed.
In the second test, the images from the simulator are replaced with the feed from an external camera connected to the computer. 
This results in a much lower cost for image retrieval and the best performance of any of the tests, with an average of 14 FPS and peaks of more than 20 FPS.
For the third and fourth tests, the image-processing calculations are moved to the onboard Raspberry Pi computer, which increases the time needed for pose-processing by one order of magnitude.
There is also a noticeable difference in performance in the Raspberry's processor between powering the computer through the AC power supply and through an external battery, stemming from the fact that the former supplies 3A of current to the board and the latter only 2A.

With these measurements, it is possible to understand how the board will behave during actual flight, with the last test being the closest to the expected flight conditions.
It should therefore be possible to sustain a performance of around 3 FPS during flight.
With a time between frames of around 0.3 seconds, and since the field of view of the camera used for flight tests is about four meters wide, the person being followed should be able to move at a speed of 3-4 m/s and remain within the view of the drone.


%% NICE TO HAVE:
%% Keyboard control actor in unreal that can walk around at a set speed
%% and be followed
%% EVEN NICER TO HAVE:
%% Web build of unreal project running dronecontrol


\clearpage