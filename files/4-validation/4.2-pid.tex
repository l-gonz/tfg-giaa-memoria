\section{PID controller design}
\label{sec:test-1-pid}

To implement the person-following mechanism effectively, a pair of PID controllers is employed to derive velocity outputs from position data obtained through image detection. These controllers are defined by their control parameters: the proportional ($K_D$), integral ($K_I$) and derivative ($K_D$) gains, as shown in Equation \ref{eq:pid}. To optimize their performance, it is necessary to fine-tune the controllers by selecting appropriate values for these parameters. These values will be determined through empirical experimentation, acknowledging that obtaining theoretical optimal values through this method, as discussed in \ref{subsec:pid-tools}, is not feasible. Nevertheless, it remains the most straightforward approach to achieve a satisfactory enough performance from the closed-loop system to validate the follow control solution. For each parameter, several values will be explored with the aim of striking a balance between a more aggressive controller (characterized by larger gains) for faster control response and a more robust controller (with smaller gains).

The procedure will be as follows. First, the sign of the process gain is selected. For the controller to operate as expected, a positive output should result in an increase in the input. If the system works in the opposite way, the feedback will lead to unstable behaviour where the process variable grows exponentially. This behaviour can be fixed by inverting the sign of the output of the controller before it is fed back into the process.

The second step will focus on selecting the control parameters mentioned before. In the initial phase, the controller operates exclusively as a pure P-controller, with both the I-portion and D-portion deactivated, thereby isolating the proportional gain ($K_P$). To find an optimal value for this parameter, different values of $K_P$ are tested systematically. Starting with a relatively low gain to ensure gradual changes in the process variable, the values are progressively increased until a distinct overshoot is observed, which should quickly diminish without noticeable oscillations.

Utilizing a P-only controller often leaves a residual control deviation, preventing the setpoint from being precisely reached. To address this residual error, it becomes necessary to introduce an integral gain that gradually compensates for the error over time. During this phase, the proportional gain remains set at the previously determined value, while the integral gain is gradually increased until the control deviation is adequately mitigated. Once again, an overly aggressive setting should be avoided to prevent undesirable oscillations.

A derivative gain can be incorporated to dampen the initial overshoot in the process variable to enhance the controller's performance further. This is accomplished by following a similar incremental approach as before. A suitable starting point for the derivative gain is typically around one-tenth of the integral gain \cite{pid-tuning}.

%------------------------------------------------

\subsubsection{The testing environment}

The outlined tuning method will be applied separately to the yaw and forward controllers, with flight control enabled exclusively in one direction at a time. For this purpose, the custom tuning tool developed for this project and detailed in Section \ref{subsec:pid-tools} will be employed to expedite the testing of various controller parameter values and their subsequent comparison. This tool allows designating which controller (yaw or forward) is enabled for testing and which parameter values will be subject to iteration. In each test, two of the parameters will be set with fixed values, while the third parameter is set sequentially to different values. For each of the values in the sequence, the new tunings are applied to the controller and its step response is plotted.

To capture the step response of the controller under focus, a deliberate offset is introduced between the vehicle and the person model within the simulation environment. This offset positions them away from the reference position at which the controller's input aligns with its setpoint. In the coordinate system of the simulation environment (AirSim), with the vehicle located at $x=0, y=0$ on the ground plane, the reference position for the person model is $x=420, y=0$. Shifting the person model from that position along either the y-axis or the x-axis will trigger a step response in the yaw or forward controller, respectively. Figure \ref{fig:tune-start-pos} shows the reference position for the controllers.

At the end of this process, the outcomes are visualized through a series of graphs generated by the program. These graphs offer insights into the controller's input and output over time and the actual changes in position and velocity recorded by the autopilot telemetry during the test. The specific telemetry variables displayed vary according to the particular controller under analysis. The graphs associated with the yaw controller show the heading and yaw speed, while those related to the forward controller show the position along the forward axis and ground speed.

Given the potential noise introduced by the image detection mechanisms, it is often more advantageous to fine-tune the controllers by examining the changes in the sensor-measured positions rather than the ones detected by computer vision mechanisms. This approach is preferred as the internal autopilot controller aids in smoothing out the resulting curves, making it easier to see trends and oscillations.


%-------------------------------------------------

\begin{figure}[H]
  \centering
  \includegraphics[width=\textwidth, keepaspectratio]{img/pid-3/tune-ref-pos.png}
  \caption{Reference position for the yaw and forward PID controllers. From left to right, the panels show the DroneVisionControl application window, the AirSim simulator world view and the world location of the human model in the simulator. The distance between the vehicle and the person is \unit[420]{cm} in the x direction and 0 in the y direction.}
  \label{fig:tune-start-pos}
\end{figure}


\subsection{Yaw controller}

The initial focus of the tuning process is on the yaw controller. As mentioned earlier, the first step entails determining the sign of the process gain. In this case, the process variable, or input to the controller, corresponds to the normalized position of the detected person in the horizontal axis of the camera's field of view. Here, a value of 0 denotes the person's location at the left edge of the field of view, while a value of 1 signifies their position at the right edge. When the controller generates a positive output, it results in a positive yaw velocity, causing the vehicle to rotate in a rightward direction. In response, the person within the camera's field of view shifts to the left, reducing the input to the controller. Given that positive outputs should lead to increasing inputs, the sign of the output velocity needs to be inverted to prevent undesired exponential growth.

A starting position must be established following the sign's determination and preceding any parameter testing. This starting position introduces an offset for the target person model relative to the reference position illustrated in Figure \ref{fig:tune-start-pos}, provoking a step response within the controller. This offset will be \unit[100]{cm} along the y-axis for the yaw controller. Given that the vehicle is positioned at the origin in the simulation environment, the person model should be situated at coordinates $x=420, y=100$ before starting the tuning process, as shown in the rightmost side of Figure \ref{fig:tune-ref-pos-yaw}. In the leftmost panel of Figure \ref{fig:tune-ref-pos-yaw}, the DroneVisionControl application displays an input of 0.64 for the yaw controller at this position. The controller will, therefore, calculate an error of e(t) = 0.5 − 0.62 (setpoint minus
input) at the start of the test.

\begin{figure}[H]
  \centering
  \includegraphics[width=\textwidth, keepaspectratio]{img/pid-3/tune-ref-pos-yaw.png}
  \caption{Starting position of the simulator for tuning the yaw controller. The human model is situated \unit[420]{cm} forward and \unit[100]{cm} to the right of the vehicle model.}
  \label{fig:tune-ref-pos-yaw}
\end{figure}

\subsubsection{Proportional component}

The proportional gain is the first parameter that needs to be tuned. The values chosen to test for $K_P$ range from 25 to 150 in steps of 25. To have a P-only controller during the test, the $K_I$ and $K_D$ components are set to 0. The results of the test are shown in Figures \ref{fig:tune-yaw-prop-io} and \ref{fig:tune-yaw-prop-measures}. The yaw controller's input and output are plotted over time in the first figure (\ref{fig:tune-yaw-prop-io}). On the left side, the input is represented by the calculated error (setpoint minus input position), and on the right side, the output is the velocity sent to the flight controller in degrees per second. The second figure (\ref{fig:tune-yaw-prop-measures}) depicts the corresponding telemetry measurements during the test, with the left graph showing the heading in degrees retrieved from the flight controller and the right graph showing the yaw velocity in degrees per second. The effects of the internal PX4 control mechanisms can be appreciated when comparing these two figures. Thanks to them, the noise introduced by the image detection features is not transmitted to the vehicle's trajectory but smoothed out.

Following the tuning process, the value selected should present a small overshoot initially and then smooth out without undue oscillation. In Figure \ref{fig:tune-yaw-prop-measures}a, the values between 75 and 125 present the initial overshoot, and from $K_P=125$ the oscillations start to be more noticeable. Therefore, the value selected for the proportional gain will be $K_P=100$. 


\begin{figure}[H]
    \begin{minipage}[t]{0.5\linewidth}
        \centering
        \scalebox{0.55}{\input{img/pid-3/tune_yaw_1.1.pgf}}
    \end{minipage}
    \begin{minipage}[t]{0.5\linewidth}
        \centering
        \scalebox{0.55}{\input{img/pid-3/tune_yaw_1.2.pgf}}
    \end{minipage}
    \caption{Variation of (a) computed error and (b) output velocity for different values of $K_{P}$ and $K_I=0$, $K_D=0$ while the yaw controller is engaged.}
    \label{fig:tune-yaw-prop-io}
\end{figure}
\begin{figure}[H]
    \begin{minipage}[t]{0.5\linewidth}
        \centering
        \scalebox{0.55}{\input{img/pid-3/tune_yaw_1.3.pgf}}
    \end{minipage}
    \begin{minipage}[t]{0.5\linewidth}
        \centering
        \scalebox{0.55}{\input{img/pid-3/tune_yaw_1.4.pgf}}
    \end{minipage}
    \caption{Variation of (a) measured yaw heading and (b) measured yaw velocity for different values of $K_{P}$ and $K_I=0$, $K_D=0$ while the yaw controller is engaged.}
    \label{fig:tune-yaw-prop-measures}
\end{figure}


\subsubsection{Integral component}

The measured positions from the P-only controller (Figure \ref{fig:tune-yaw-der-measures}a) show a remaining deviation from the target heading after the controller reaches an equilibrium. This common occurrence in P-controllers is solved by adding an integral component. The gain for this component can be decided in the same manner as the proportional part. In this case, the $K_P$ value will be set to 100, as decided in the previous section, and the $K_D$ will remain at 0. Thus, the controller is being tested as a PI-controller. The values chosen for $K_I$ for the test range from 0 to 50 in steps of 10. The results for the computed error and the measured vehicle heading obtained by running the tuning tool with those values can be seen in Figure \ref{fig:tune-yaw-int}. The additional velocity graphs produced by the tool can be consulted in Appendix \ref{app:fwd-pid-results}. Looking at Figure \ref{fig:tune-yaw-int}, it can be noted that for $K_I$ of 30 or more, the final heading ends up very close to the target, eliminating the remaining deviation detected in the previous section. From these values, the selected one will be $K_I=40$, as it offers the best balance between reaching the target as fast as possible and not showing undesirable oscillation after the initial overshoot.

\begin{figure}[H]
    \begin{minipage}[t]{0.5\linewidth}
        \centering
        \scalebox{0.55}{\input{img/pid-3/tune_yaw_2.1.pgf}}
    \end{minipage}
    \begin{minipage}[t]{0.5\linewidth}
        \centering
        \scalebox{0.55}{\input{img/pid-3/tune_yaw_2.3.pgf}}
    \end{minipage}
    \caption{Variation of (a) computed error and (b) measured yaw heading for different values of $K_{I}$ and $K_P=100$, $K_D=0$ while the yaw controller is engaged.}
    \label{fig:tune-yaw-int}
\end{figure}

\subsubsection{Derivative component}

The last component in a PID controller is the derivative part. This component can help improve the performance by dampening oscillations in the controller output, thus allowing the selection of a higher $K_P$ that would otherwise be possible. However, noise in the input signal to the controller (like the one generated by the image detection mechanisms) is known to degrade the derivative action since spikes in the input cause significant contributions from the derivative part \cite{pid-derivative-noise}. To observe the effect of this component, the tuning tool has been run with a fixed value of $K_P=100$ and $K_I=40$. The results for the computed error and the measured vehicle heading can be seen in Figure \ref{fig:tune-yaw-der}. The additional velocity graphs produced by the tool can be consulted in Appendix \ref{app:fwd-pid-results}. For all of the tested values between 5 and 80, the performance of the controller clearly decreases, creating more oscillations the higher the value of $K_D$. There are ways of getting around the noise limitations to take advantage of the derivative part, like adding filters to the controller's input \cite{pid-derivative-fixes}. However, for this particular application, it is enough to settle for a PI-controller and leave out the derivative part altogether.

\begin{figure}[H]
    \begin{minipage}[t]{0.5\linewidth}
        \centering
        \scalebox{0.55}{\input{img/pid-3/tune_yaw_3.1.pgf}}
    \end{minipage}
    \begin{minipage}[t]{0.5\linewidth}
        \centering
        \scalebox{0.55}{\input{img/pid-3/tune_yaw_3.3.pgf}}
    \end{minipage}
    \caption{Variation of (a) computed error and (b) measured yaw heading for different values of $K_{D}$ and $K_P=100$, $K_I=40$ while the yaw controller is engaged.}
    \label{fig:tune-yaw-der}
\end{figure}


Then, the final values chosen for the yaw controller's parameters are $K_P=100$, $K_I=40$ and $K_D=0$. These values constitute only a rough estimate of adequate component gains that produce a good enough controller response for the follow solution to be validated. The trial-and-error tuning method employed also showcases an additional application for the simulation environment offered by PX4 and Airsim. There exist many computational methods of higher complexity that can obtain more optimal parameters for the controllers, but they fall out of the scope of this project.

\subsection{Forward controller}

Once the yaw controller has been tuned, the focus shifts to the forward controller. The tuning process for the forward controller mirrors that of the yaw controller. When examining the process gain in this context, it becomes evident that a positive output generated by the controller induces a positive velocity in the forward direction, bringing the vehicle closer to the target person. The input variable is determined by the height of the detected person within the camera's field of view, normalized to the height of the field of view itself. This value increases as the drone approaches the target. Consequently, a positive output velocity naturally leads to an increasing input to the controller, indicating that the controller gain is already set to the correct sign.

Regarding the start position for the environment to tune the forward controller, in this case, an offset is required in terms of the distance between the person and the vehicle along the x-axis. To achieve this offset, the person model will be positioned at coordinates $x=320, y=0$, while the vehicle remains at the origin within the simulated world. This chosen starting position, which sets the person and the vehicle closer together than at the reference point, will result in an initially negative velocity output as the vehicle moves away from the person. Figure \ref{fig:tune-ref-pos-fwd} illustrates this starting position within the simulator. In the leftmost panel of Figure \ref{fig:tune-ref-pos-fwd}, the DroneVisionControl application displays an input of 0.69 for the yaw controller at this position. The controller will, therefore, calculate an error of e(t) = 0.5 − 0.69 (setpoint minus input) at the start of the test.

\begin{figure}[H]
  \centering
  \includegraphics[width=\textwidth, keepaspectratio]{img/pid-3/tune-ref-pos-fwd.png}
  \caption{Starting position of the simulator for tuning the forward controller. The human model is situated \unit[420]{cm} forward and centred from the vehicle position.}\label{fig:tune-ref-pos-fwd}
\end{figure}

The process to select the component gains for the forward controller runs similarly to the yaw controller. The plotted outputs from the tuning utility are contained in Appendix \ref{app:fwd-pid-results}. Based on those graphs, the selected values for the parameters are $K_P=4$, $K_I=1$ and $K_D=0$.


\subsection{PID controller validation}
\label{subsec:pid-test-controller}

The chosen values for the controllers can now be applied to the complete follow solution to get a clearer picture of the expected performance of the vehicle during flight tests. In this test, the follow application is started, and the drone is made to take off and switch flight mode to offboard control. After the person is detected by the pose mechanisms, the 3D-model is moved around in the simulated world to observe how the vehicle reacts. The expected result is that the movement is appreciatively more responsive than on the follow test run with the non-tuned P-only controller at the end of Section \ref{sec:test-3-airsim} (\emph{Verify integration with follow solution}). To provide a visual demonstration, a video showcasing the test described can be accessed \href{https://l-gonz.github.io/tfg-giaa-dronecontrol/videos/test-sitl-follow}{here}\footnote{\url{https://l-gonz.github.io/tfg-giaa-dronecontrol/videos/test-sitl-follow}}. Additionally, Figure \ref{fig:airsim-test-follow} displays a frame extracted from the video, giving a glimpse of the drone's behaviour during the follow operation.

\begin{figure}[H]
  \centering
  \includegraphics[width=\textwidth, keepaspectratio]{img/video-follow-sitl.png}
  \caption{Single frame from the video showing the movement of the drone in response to changes in the position of the tracked person.}\label{fig:airsim-test-follow}
\end{figure}

